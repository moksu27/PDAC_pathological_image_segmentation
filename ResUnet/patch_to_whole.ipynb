{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim.adam import Adam\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import datetime\n",
    "import pytz\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import re\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 맥 mps 설정\\ndevice = torch.device(\"mps:0\" if torch.backends.mps.is_available() else \"cpu\")\\nprint(f\"현재 디바이스는 {device} 입니다.\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 맥 mps 설정\n",
    "device = torch.device(\"mps:0\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"현재 디바이스는 {device} 입니다.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':512,\n",
    "    'EPOCHS':50,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'SEED':41,\n",
    "    'MEAN' : [0.485, 0.456, 0.406],\n",
    "    'STD'  : [0.229, 0.224, 0.225],\n",
    "    'train_magnification':\"20X\",\n",
    "    'test_magnification':\"20X\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023_06_08_05:26_PM\n"
     ]
    }
   ],
   "source": [
    "kst = pytz.timezone('Asia/Seoul')\n",
    "current_datetime = datetime.datetime.now(kst)\n",
    "formatted_datetime = current_datetime.strftime(\"%Y_%m_%d_%I:%M_%p\")\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pth_name:/data/pthfile/train:20X_test:20X_epoch:50_(2023_06_08_05:26_PM).pth\n",
      "score_path:/data/output/Loss_Score\n",
      "figure_path:/data/output/figure/figure_train:20X_test:20X_epoch:50_(2023_06_08_05:26_PM)\n",
      "test_data_path:/data/PDA_mask_img/test_mask/20X/**/*.png\n"
     ]
    }
   ],
   "source": [
    "# server path\n",
    "pth_name=f\"/data/pthfile/train:{CFG['train_magnification']}_test:{CFG['test_magnification']}_epoch:{CFG['EPOCHS']}_({formatted_datetime}).pth\"\n",
    "output_name = f\"train:{CFG['train_magnification']}_test:{CFG['test_magnification']}_epoch:{CFG['EPOCHS']}\"\n",
    "score_path = f\"/data/output/Loss_Score\"\n",
    "figure_path = f\"/data/output/figure/figure_{output_name}_({formatted_datetime})\"\n",
    "test_data_path = f\"/data/PDA_mask_img/test_mask/{CFG['test_magnification']}/**/*.png\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"pth_name:{pth_name}\")\n",
    "print(f\"score_path:{score_path}\")\n",
    "print(f\"figure_path:{figure_path}\")\n",
    "print(f\"test_data_path:{test_data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npth_name=f\"git_ignore/pthfile/train:{CFG[\\'train_magnification\\']}X_test:{CFG[\\'test_magnification\\']}X_epoch:{CFG[\\'EPOCHS\\']}_({formatted_datetime}).pth\"\\noutput_name = f\"train:{CFG[\\'train_magnification\\']}X_test:{CFG[\\'test_magnification\\']}X_epoch:{CFG[\\'EPOCHS\\']}\"\\nscore_path = f\"git_ignore/output/Loss_Score/score_{output_name}_({formatted_datetime})\"\\nfigure_path = f\"git_ignore/output/figure/figure_{output_name}_({formatted_datetime})\"\\ntrain_data_path = f\"git_ignore/PDA_mask_img/train/{CFG[\\'train_magnification\\']}X/**/*.png\"\\ntest_data_path = f\"git_ignore/PDA_mask_img/test/{CFG[\\'test_magnification\\']}X/**/*.png\"\\nval_data_path = f\"git_ignore/PDA_mask_img/validation/{CFG[\\'train_magnification\\']}X/**/*.png\"\\n\\n\\nprint(f\"pth_name:{pth_name}\")\\nprint(f\"output_path:{output_path}\")\\nprint(f\"figure_path:{figure_path}\")\\nprint(f\"train_data_path:{train_data_path}\")\\nprint(f\"test_data_path:{test_data_path}\")\\nprint(f\"test_data_path:{val_data_path}\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local path\n",
    "'''\n",
    "pth_name=f\"git_ignore/pthfile/train:{CFG['train_magnification']}X_test:{CFG['test_magnification']}X_epoch:{CFG['EPOCHS']}_({formatted_datetime}).pth\"\n",
    "output_name = f\"train:{CFG['train_magnification']}X_test:{CFG['test_magnification']}X_epoch:{CFG['EPOCHS']}\"\n",
    "score_path = f\"git_ignore/output/Loss_Score/score_{output_name}_({formatted_datetime})\"\n",
    "figure_path = f\"git_ignore/output/figure/figure_{output_name}_({formatted_datetime})\"\n",
    "train_data_path = f\"git_ignore/PDA_mask_img/train/{CFG['train_magnification']}X/**/*.png\"\n",
    "test_data_path = f\"git_ignore/PDA_mask_img/test/{CFG['test_magnification']}X/**/*.png\"\n",
    "val_data_path = f\"git_ignore/PDA_mask_img/validation/{CFG['train_magnification']}X/**/*.png\"\n",
    "\n",
    "\n",
    "print(f\"pth_name:{pth_name}\")\n",
    "print(f\"output_path:{output_path}\")\n",
    "print(f\"figure_path:{figure_path}\")\n",
    "print(f\"train_data_path:{train_data_path}\")\n",
    "print(f\"test_data_path:{test_data_path}\")\n",
    "print(f\"test_data_path:{val_data_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 경로지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/PDA_mask_img/test_mask/20X/C3L-01637-21/C3L-01637-21 [d=1.01174,x=10360,y=3108,w=518,h=518]-labelled.png',\n",
       " '/data/PDA_mask_img/test_mask/20X/C3L-01637-21/C3L-01637-21 [d=1.01174,x=10360,y=3626,w=518,h=518]-labelled.png',\n",
       " '/data/PDA_mask_img/test_mask/20X/C3L-01637-21/C3L-01637-21 [d=1.01174,x=10360,y=4144,w=518,h=518]-labelled.png',\n",
       " '/data/PDA_mask_img/test_mask/20X/C3L-01637-21/C3L-01637-21 [d=1.01174,x=10360,y=4662,w=518,h=518]-labelled.png',\n",
       " '/data/PDA_mask_img/test_mask/20X/C3L-01637-21/C3L-01637-21 [d=1.01174,x=10878,y=3626,w=518,h=518]-labelled.png']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path_list = sorted(glob.glob(test_data_path))\n",
    "test_mask_path = test_path_list[0::2]\n",
    "test_img_path = test_path_list[1::2]\n",
    "test_mask_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path, mask_path, transform = None):\n",
    "        self.image = img_path\n",
    "        self.mask = mask_path\n",
    "        \n",
    "        n_samples =  len(self.image)\n",
    "        \n",
    "        # 데이터 미리 섞어줌\n",
    "        np.random.seed(CFG['SEED'])\n",
    "        idxs = np.random.permutation(range(n_samples))\n",
    "        \n",
    "        self.image = np.array(self.image)[idxs]\n",
    "        self.mask = np.array(self.mask)[idxs]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image) # 데이터셋 길이\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = np.array(Image.open(self.image[i]))\n",
    "        mask = np.array(Image.open(self.mask[i]))\n",
    "        data = self.transform(image = image, mask = mask)\n",
    "        image = data[\"image\"]\n",
    "        mask = data[\"mask\"]\n",
    "        return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = A.Compose([\n",
    "        A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "        A.Normalize(mean=CFG['MEAN'], std = CFG['STD']),\n",
    "        ToTensorV2(transpose_mask=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터\n",
    "test_set = CustomDataset(img_path = test_img_path,\n",
    "                         mask_path= test_mask_path,\n",
    "                         transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(test_set, batch_size = CFG[\"BATCH_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data : 81\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_data : {len(test_set)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = models.resnet18(pretrained=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.upconv1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.encoder.conv1(x)\n",
    "        x1 = self.encoder.bn1(x1)\n",
    "        x1 = self.encoder.relu(x1)\n",
    "        x1 = self.encoder.maxpool(x1)\n",
    "\n",
    "        x2 = self.encoder.layer1(x1)\n",
    "        x3 = self.encoder.layer2(x2)\n",
    "        x4 = self.encoder.layer3(x3)\n",
    "        x5 = self.encoder.layer4(x4)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.upconv1(x5)\n",
    "        x = torch.cat((x, x4), dim=1)\n",
    "        x = self.relu(self.conv1(x))\n",
    "\n",
    "        x = self.upconv2(x)\n",
    "        x = torch.cat((x, x3), dim=1)\n",
    "        x = self.relu(self.conv2(x))\n",
    "\n",
    "        x = self.upconv3(x)\n",
    "        x = torch.cat((x, x2), dim=1)\n",
    "        x = self.relu(self.conv3(x))\n",
    "\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        # Resize to 512x512\n",
    "        x = nn.functional.interpolate(x, size=(512, 512), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        inputs = F.sigmoid(inputs) # sigmoid를 통과한 출력이면 주석처리\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 학습 파라미터\n",
    "model = UNet(num_classes=1).to(device)\n",
    "model = nn.DataParallel(model)\n",
    "optimizer = Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "criterion = DiceLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(pred, target, smooth=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균값 계산\n",
    "class AverageMeter: \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStop:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_meter = AverageMeter()\n",
    "score_meter = AverageMeter()\n",
    "early_stopping = EarlyStop(patience = 20, delta = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"data/pthfile/train:20X_test:20X_epoch:50_(2023_06_07_03:24_PM).pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_set)):\n",
    "    \n",
    "    data, label = test_set[i]\n",
    "    label = torch.squeeze(label)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(torch.unsqueeze(data, dim=0).to(device))\n",
    "    out = torch.squeeze(out).sigmoid().to('cpu')\n",
    "    pred = torch.ge(out, 0.5).float().to('cpu')\n",
    "    pred_array = pred.numpy() * 255\n",
    "    pred_array = pred_array.astype(np.uint8)\n",
    "    coordinates = re.search(r'x=(\\d+),y=(\\d+)', test_set.mask[i])\n",
    "    cv2.imwrite(f'data/output/pred/{coordinates[0]}.png',pred_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
