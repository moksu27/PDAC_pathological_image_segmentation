{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset.semi import SemiDataset\n",
    "from model.semseg.deeplabv3plus import DeepLabV3Plus\n",
    "from supervised import evaluate\n",
    "from util.ohem import ProbOhemCrossEntropy2d\n",
    "from util.utils import AverageMeter\n",
    "from util.dist_helper import setup_distributed\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':1024,\n",
    "    'crop_size': 256,\n",
    "    'EPOCHS':50,\n",
    "    'lr': 0.004,\n",
    "    'lr_multi': 10.0,\n",
    "    'BATCH_SIZE': 10,\n",
    "    'SEED':41,\n",
    "    'num_worker':4,\n",
    "    'MEAN' : [0.485, 0.456, 0.406],\n",
    "    'STD'  : [0.229, 0.224, 0.225],\n",
    "    'train_magnification':\"20X\",\n",
    "    'dataset':\"pathology\",\n",
    "    'nclass': 2,\n",
    "    'criterion':\"CELoss\",\n",
    "    'ignore_index': 255,\n",
    "    'conf_thresh': 0.95,\n",
    "    'backbone': 'xception',\n",
    "    'dilations': [6, 12, 18]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data_path = f\"/workspace/git_ignore/PDA_labeled_tile(1024)/train/{CFG['train_magnification']}/**/*.png\"\n",
    "unlabeled_data_path = f\"/workspace/git_ignore/PDA_unlabeled_tile(1024)/**/*_tiles/*.png\"\n",
    "val_data_path = f\"/workspace/git_ignore/PDA_labeled_tile(1024)/validation/{CFG['train_magnification']}/**/*.png\"\n",
    "pth_path = \"/workspace/FixMatch/pthfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_train_list = sorted(glob(labeled_data_path))\n",
    "labeld_train_img = labeled_train_list[1::2]\n",
    "labeld_train_mask = labeled_train_list[0::2]\n",
    "\n",
    "val_path_list = sorted(glob(val_data_path))\n",
    "val_img = val_path_list[1::2]\n",
    "val_mask = val_path_list[0::2]\n",
    "\n",
    "unlabeled_train_img = sorted(glob(unlabeled_data_path))\n",
    "unlabeled_train_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    rank, world_size = setup_distributed(port=\"tcp://0.0.0.0:12345\")\n",
    "\n",
    "    cudnn.enabled = True\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    model = DeepLabV3Plus(CFG)\n",
    "\n",
    "    optimizer = SGD([{'params': model.backbone.parameters(), 'lr': CFG['lr']},\n",
    "                     {'params': [param for name, param in model.named_parameters() if 'backbone' not in name],\n",
    "                      'lr': CFG['lr'] * CFG['lr_multi']}], lr=CFG['lr'], momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model.cuda()\n",
    "\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank], broadcast_buffers=False,\n",
    "                                                      output_device=local_rank, find_unused_parameters=False)\n",
    "\n",
    "    if CFG['criterion'] == 'CELoss':\n",
    "        criterion_l = nn.CrossEntropyLoss(ignore_index = CFG['ignore_index']).cuda(local_rank)\n",
    "    elif CFG['criterion'] == 'OHEM':\n",
    "        criterion_l = ProbOhemCrossEntropy2d(ignore_index = CFG['ignore_index']).cuda(local_rank)\n",
    "\n",
    "\n",
    "    criterion_u = nn.CrossEntropyLoss(reduction='none').cuda(local_rank)\n",
    "\n",
    "    trainset_u = SemiDataset(img = unlabeled_train_img, mask = unlabeled_train_mask, mode = 'train_u', size = CFG['crop_size'])\n",
    "    trainset_l = SemiDataset(img = labeld_train_img, mask = labeld_train_mask, mode = 'train_l', size = CFG['crop_size'])\n",
    "    valset = SemiDataset(img = val_img, mask = val_mask, mode = 'val', size = CFG['crop_size'])\n",
    "\n",
    "    trainsampler_l = torch.utils.data.distributed.DistributedSampler(trainset_l)\n",
    "    trainloader_l = DataLoader(trainset_l, batch_size=CFG['batch_size'],\n",
    "                               pin_memory=True, num_workers=CFG['num_worker'], drop_last=True, sampler=trainsampler_l)\n",
    "    trainsampler_u = torch.utils.data.distributed.DistributedSampler(trainset_u)\n",
    "    trainloader_u = DataLoader(trainset_u, batch_size=CFG['batch_size'],\n",
    "                               pin_memory=True, num_workers=CFG['num_worker'], drop_last=True, sampler=trainsampler_u)\n",
    "    valsampler = torch.utils.data.distributed.DistributedSampler(valset)\n",
    "    valloader = DataLoader(valset, batch_size=1, pin_memory=True, num_workers=CFG['num_worker'],\n",
    "                           drop_last=False, sampler=valsampler)\n",
    "\n",
    "    total_iters = len(trainloader_u) * CFG['EPOCHS']\n",
    "    previous_best = 0.0\n",
    "\n",
    "    if os.path.exists(os.path.join(pth_path, 'latest.pth')):\n",
    "        checkpoint = torch.load(os.path.join(pth_path, 'latest.pth'))\n",
    "        model.load_state_dict(checkpoint['model'], map_location = device)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'], map_location = device)\n",
    "        epoch = checkpoint['epoch']\n",
    "        previous_best = checkpoint['previous_best']\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f'************ Load from checkpoint at epoch {epoch}')\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        if rank == 0:\n",
    "            print(f'===========> Epoch: {epoch}, LR: {optimizer.param_groups[0][\"lr\"]:.5f}, Previous best: {previous_best:.2f}')\n",
    "\n",
    "        total_loss  = AverageMeter()\n",
    "        total_loss_x = AverageMeter()\n",
    "        total_loss_s = AverageMeter()\n",
    "        total_mask_ratio = AverageMeter()\n",
    "\n",
    "        trainloader_l.sampler.set_epoch(epoch)\n",
    "        trainloader_u.sampler.set_epoch(epoch)\n",
    "\n",
    "        loader = zip(trainloader_l, trainloader_u, trainloader_u)\n",
    "\n",
    "        for i, ((img_x, mask_x),\n",
    "                (img_u_w, img_u_s, _, ignore_mask, cutmix_box, _),\n",
    "                (img_u_w_mix, img_u_s_mix, _, ignore_mask_mix, _, _)) in tqdm(enumerate(loader)):\n",
    "\n",
    "            img_x, mask_x = img_x.cuda(), mask_x.cuda()\n",
    "            img_u_w, img_u_s = img_u_w.cuda(), img_u_s.cuda()\n",
    "            ignore_mask, cutmix_box = ignore_mask.cuda(), cutmix_box.cuda()\n",
    "            img_u_w_mix, img_u_s_mix = img_u_w_mix.cuda(), img_u_s_mix.cuda()\n",
    "            ignore_mask_mix = ignore_mask_mix.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                pred_u_w_mix = model(img_u_w_mix).detach()\n",
    "                conf_u_w_mix = pred_u_w_mix.softmax(dim=1).max(dim=1)[0]\n",
    "                mask_u_w_mix = pred_u_w_mix.argmax(dim=1)\n",
    "\n",
    "            img_u_s[cutmix_box.unsqueeze(1).expand(img_u_s.shape) == 1] = img_u_s_mix[cutmix_box.unsqueeze(1).expand(img_u_s.shape) == 1]\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            num_lb, num_ulb = img_x.shape[0], img_u_w.shape[0]\n",
    "\n",
    "            pred_x, pred_u_w = model(torch.cat((img_x, img_u_w))).split([num_lb, num_ulb])\n",
    "            pred_u_s = model(img_u_s)\n",
    "\n",
    "            pred_u_w = pred_u_w.detach()\n",
    "            conf_u_w = pred_u_w.softmax(dim=1).max(dim=1)[0]\n",
    "            mask_u_w = pred_u_w.argmax(dim=1)\n",
    "\n",
    "            mask_u_w_cutmixed, conf_u_w_cutmixed, ignore_mask_cutmixed = (mask_u_w.clone(), conf_u_w.clone(), ignore_mask.clone())\n",
    "\n",
    "            mask_u_w_cutmixed[cutmix_box == 1] = mask_u_w_mix[cutmix_box == 1]\n",
    "            conf_u_w_cutmixed[cutmix_box == 1] = conf_u_w_mix[cutmix_box == 1]\n",
    "            ignore_mask_cutmixed[cutmix_box == 1] = ignore_mask_mix[cutmix_box == 1]\n",
    "\n",
    "            loss_x = criterion_l(pred_x, mask_x)\n",
    "\n",
    "            loss_u_s = criterion_u(pred_u_s, mask_u_w_cutmixed)\n",
    "            loss_u_s = loss_u_s * ((conf_u_w_cutmixed >= CFG['conf_thresh']) & (ignore_mask_cutmixed != 255))\n",
    "            loss_u_s = loss_u_s.sum() / (ignore_mask_cutmixed != 255).sum().item()\n",
    "\n",
    "            loss = (loss_x + loss_u_s) / 2.0\n",
    "\n",
    "            torch.distributed.barrier()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss.update(loss.item())\n",
    "            total_loss_x.update(loss_x.item())\n",
    "            total_loss_s.update(loss_u_s.item())\n",
    "            mask_ratio = ((conf_u_w >= CFG['conf_thresh']) & (ignore_mask != 255)).sum().item() / (ignore_mask != 255).sum()\n",
    "            total_mask_ratio.update(mask_ratio.item())\n",
    "\n",
    "            iters = (epoch-1) * len(trainloader_u) + i\n",
    "            lr = CFG['lr'] * (1 - iters / total_iters) ** 0.9\n",
    "            optimizer.param_groups[0][\"lr\"] = lr\n",
    "            optimizer.param_groups[1][\"lr\"] = lr * CFG['lr_multi']\n",
    "        \n",
    "        eval_mode = 'sliding_window' if CFG['dataset'] == 'cityscapes' else 'original'\n",
    "        mIoU = evaluate(model, valloader, eval_mode, CFG)\n",
    "\n",
    "        if rank == 0:\n",
    "            print(f\"epoch{epoch}: Total Loss:{total_loss.avg:.2f} Loss x:{total_loss_x.avg:.2f}\\\n",
    "                  Loss s:{total_loss_s.avg:.2f} Mask ratio:{total_mask_ratio.avg:.2f} Val mIOU:{mIoU:.2f}\")\n",
    "            with mlflow.start_run(run_name=CFG[\"train_magnification\"], experiment_id=210481695216345952):\n",
    "                mlflow.log_metric('Total_Loss', total_loss.avg)\n",
    "                mlflow.log_metric('Loss_x', total_loss_x.avg)\n",
    "                mlflow.log_metric('Loss_s', total_loss_s.avg)\n",
    "                mlflow.log_metric('Mask_ratio', total_mask_ratio.avg)\n",
    "                mlflow.log_metric('Val mIOU', mIoU)\n",
    "                mlflow.end_run()\n",
    "\n",
    "\n",
    "        is_best = mIoU > previous_best\n",
    "        previous_best = max(mIoU, previous_best)\n",
    "        if rank == 0:\n",
    "            checkpoint = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'previous_best': previous_best,\n",
    "            }\n",
    "            torch.save(checkpoint, os.path.join(pth_path, 'latest.pth'))\n",
    "            if is_best:\n",
    "                torch.save(checkpoint, os.path.join(pth_path, 'best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
